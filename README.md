üè• MedTech Compliance Audit Engine (MVP)

Status: Phase 1 Completed (Knowledge Base Ingestion)

Client: Geister MedTech

Tech Stack: Azure Native (AI Search, OpenAI, Doc Intelligence)
üéØ Vision

Dieses System automatisiert die regulatorische √úberwachung und GAP-Analyse f√ºr MedTech-Hersteller. Es l√∂st das Problem der manuellen Pr√ºfung von internen SOPs gegen sich st√§ndig √§ndernde regulatorische Anforderungen (MDR, IVDR, MDCG).

Anders als einfache "Chat with PDF"-L√∂sungen nutzt dieses System eine Multi-Stage Refinement Pipeline, um sicherzustellen, dass kritische regulatorische Nuancen (Fu√ünoten, Querverweise, Tabellen-Qualifier) nicht durch technisches Chunking verloren gehen.
üèó Architektur der Daten-Pipeline

Der Prozess transformiert unstrukturierte PDFs (Leitlinien) in eine hochpr√§zise, durchsuchbare Vektor-Datenbank.
Code snippet

graph LR
    A[PDF Input] -->|Azure Doc Intelligence| B(Raw Markdown)
    B -->|GPT-5.1 Semantic Cleaning| C(Refined Markdown)
    C -->|Semantic Chunking| D(JSON Chunks)
    D -->|Text-Embedding-3-Large| E[(Azure AI Search)]

Die 4 Phasen der Pipeline

    Ingestion (ingest_manager.py)

        Nutzung des Azure AI Document Intelligence (Layout Model).

        Extraktion von visueller Struktur (Tabellen, Header, Paragraphen) anstatt reinem Text.

        Output: _raw.md Dateien.

    Refinement (refine_manager.py)

        AI-Driven Cleaning: Ein LLM (GPT-5.1/GPT-4o) liest das Dokument.

        Context Repair: Fu√ünoten am Seitenende werden semantisch an ihre Referenz im Text verschoben.

        Noise Reduction: Entfernung von Seitenzahlen, Kopfzeilen und Artefakten.

        Output: _cleaned.md Dateien (Human Readable).

    Conversion (mdcg_to_json.py)

        Semantic Chunking: Splitting basierend auf Markdown-Headern (#, ##), nicht willk√ºrlichen Token-Grenzen.

        Metadata Enrichment: Hinzuf√ºgen von Hierarchie-Pfaden (Chapter > Section).

        Output: Granulare JSON-Dateien pro Dokument.

    Indexing (upload_manager.py)

        Generierung von Vektoren mittels text-embedding-3-large (3072 Dimensionen).

        Upload in den Azure AI Search Index (mdr-legal-index-v1).

        Merge von MDR (HTML-Source) und MDCG (PDF-Source) in ein einheitliches Schema.

üöÄ Installation & Setup
1. Umgebungsvariablen (.env)

Erstelle eine .env Datei im Root-Verzeichnis mit folgenden Schl√ºsseln:
Ini, TOML

# --- AZURE SEARCH (Vektor Datenbank) ---
AZURE_SEARCH_ENDPOINT="https://DEIN-SEARCH.search.windows.net"
AZURE_SEARCH_KEY="DEIN-ADMIN-KEY"
AZURE_SEARCH_INDEX="mdr-legal-index-v1"

# --- AZURE OPENAI: EMBEDDINGS (F√ºr Vektoren) ---
AZURE_OPENAI_EMBEDDING_ENDPOINT="https://DEIN-AI-RESSOURCE-1.openai.azure.com/"
AZURE_OPENAI_EMBEDDING_KEY="KEY-1"
AZURE_OPENAI_EMBEDDING_DEPLOYMENT="text-embedding-3-large"
AZURE_OPENAI_EMBEDDING_API_VERSION="2024-02-01"

# --- AZURE OPENAI: CHAT / REFINER (F√ºr Cleaning) ---
AZURE_OPENAI_CHAT_ENDPOINT="https://DEIN-AI-RESSOURCE-2.openai.azure.com/"
AZURE_OPENAI_CHAT_KEY="KEY-2"
AZURE_OPENAI_CHAT_DEPLOYMENT="gpt-5.1-chat"
AZURE_OPENAI_CHAT_API_VERSION="2024-12-01-preview"

# --- AZURE DOCUMENT INTELLIGENCE (OCR) ---
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT="https://DEIN-DOC-INTEL.cognitiveservices.azure.com/"
AZURE_DOCUMENT_INTELLIGENCE_KEY="DEIN-KEY"

# --- LOKALE PFADE (Konfigurierbar) ---
INPUT_PDF_PATH="data/input"           # Hier PDFs ablegen
OUTPUT_MD_PATH="data/output"          # Zwischenspeicher Raw MD
OUTPUT_MD_PATH_REFINED="data/refined" # Zwischenspeicher Clean MD
OUTPUT_JSON_PATH="data/json"          # Ready for Upload

2. Dependencies installieren
Bash

pip install azure-search-documents azure-ai-documentintelligence openai langchain langchain-text-splitters python-dotenv pydantic tiktoken

üíª Nutzung

Um die gesamte Pipeline (vom PDF bis zum Index) auszuf√ºhren:
Bash

python main.py

Das Skript f√ºhrt alle Schritte sequenziell aus und bricht bei Fehlern ab, um Dateninkonsistenzen zu vermeiden.

Einzelne Module testen:

    Nur OCR testen: python ingest_manager.py

    Nur Cleaning testen: python refine_manager.py

    Nur Upload wiederholen: python upload_manager.py

üìÇ Projektstruktur

.
‚îú‚îÄ‚îÄ main.py                 # Orchestrator Script
‚îú‚îÄ‚îÄ ingest_manager.py       # Phase 1: PDF zu Markdown (Azure ADI)
‚îú‚îÄ‚îÄ refine_manager.py       # Phase 2: Markdown Cleaning (LLM)
‚îú‚îÄ‚îÄ mdcg_to_json.py         # Phase 3: Markdown zu JSON Chunks
‚îú‚îÄ‚îÄ upload_manager.py       # Phase 4: JSON zu Azure Search
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Pydantic Data Models (MDRChunk)
‚îÇ   ‚îî‚îÄ‚îÄ mdr_parser.py       # Legacy: HTML Scraper f√ºr MDR Gesetzestexte
‚îú‚îÄ‚îÄ data/                   # Lokaler Datenspeicher (Gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ input/              # Dropzone f√ºr PDFs
‚îÇ   ‚îú‚îÄ‚îÄ refined/            # Quality Check Zone
‚îÇ   ‚îî‚îÄ‚îÄ json/               # Upload Zone
‚îî‚îÄ‚îÄ .env                    # Secrets

‚ö†Ô∏è Disclaimer

Dieses Tool dient zur Unterst√ºtzung von Regulatory Affairs Managern. Die Ergebnisse der KI (insbesondere beim Cleaning) m√ºssen stichprobenartig validiert werden. Es ersetzt keine Benannte Stelle (Notified Body).